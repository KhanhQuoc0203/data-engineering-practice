[2025-05-09T15:02:56.053+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: exercises_pipeline.Exercise-3.run_exercise-3 manual__2025-05-06T19:44:56.298401+00:00 [queued]>
[2025-05-09T15:02:56.062+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: exercises_pipeline.Exercise-3.run_exercise-3 manual__2025-05-06T19:44:56.298401+00:00 [queued]>
[2025-05-09T15:02:56.063+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 2
[2025-05-09T15:02:56.079+0000] {taskinstance.py:2191} INFO - Executing <Task(BashOperator): Exercise-3.run_exercise-3> on 2025-05-06 19:44:56.298401+00:00
[2025-05-09T15:02:56.084+0000] {standard_task_runner.py:60} INFO - Started process 315 to run task
[2025-05-09T15:02:56.088+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'exercises_pipeline', 'Exercise-3.run_exercise-3', 'manual__2025-05-06T19:44:56.298401+00:00', '--job-id', '26', '--raw', '--subdir', 'DAGS_FOLDER/exercises_dag.py', '--cfg-path', '/tmp/tmpt7qmu5qf']
[2025-05-09T15:02:56.091+0000] {standard_task_runner.py:88} INFO - Job 26: Subtask Exercise-3.run_exercise-3
[2025-05-09T15:02:56.141+0000] {task_command.py:423} INFO - Running <TaskInstance: exercises_pipeline.Exercise-3.run_exercise-3 manual__2025-05-06T19:44:56.298401+00:00 [running]> on host c423529483b0
[2025-05-09T15:02:56.229+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='exercises_pipeline' AIRFLOW_CTX_TASK_ID='Exercise-3.run_exercise-3' AIRFLOW_CTX_EXECUTION_DATE='2025-05-06T19:44:56.298401+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-05-06T19:44:56.298401+00:00'
[2025-05-09T15:02:56.231+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2025-05-09T15:02:56.233+0000] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', 'cd /opt/***/app/Exercise-3 && python main.py']
[2025-05-09T15:02:56.241+0000] {subprocess.py:86} INFO - Output:
[2025-05-09T15:03:00.486+0000] {subprocess.py:93} INFO - Attempting to download https://data.commoncrawl.org/crawl-data/CC-MAIN-2022-05/wet.paths.gz...
[2025-05-09T15:03:00.488+0000] {subprocess.py:93} INFO - Error downloading wet.paths.gz: Failed to download https://data.commoncrawl.org/crawl-data/CC-MAIN-2022-05/wet.paths.gz: HTTPSConnectionPool(host='data.commoncrawl.org', port=443): Max retries exceeded with url: /crawl-data/CC-MAIN-2022-05/wet.paths.gz (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f0eab3d0dc0>: Failed to establish a new connection: [Errno -2] Name or service not known'))
[2025-05-09T15:03:00.504+0000] {subprocess.py:97} INFO - Command exited with return code 0
[2025-05-09T15:03:00.531+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=exercises_pipeline, task_id=Exercise-3.run_exercise-3, execution_date=20250506T194456, start_date=20250509T150256, end_date=20250509T150300
[2025-05-09T15:03:00.565+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2025-05-09T15:03:00.591+0000] {taskinstance.py:3280} INFO - 1 downstream tasks scheduled from follow-on schedule check
